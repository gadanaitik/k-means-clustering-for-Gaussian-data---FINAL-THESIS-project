In this project, we have demonstrated the superiority of using the inter-cluster distance in the \textit{k}-means clustering. By including the ICD along with the WCD, the new proposed algorithm was able to outperform the traditional \textit{k}-means across a variety of data sets with different dimensions and clusters. It is widely known that \textit{k}-means clustering is a popular unsupervised clustering method that is heavily reliant on the prior knowledge of the number of clusters in a data set. The evaluation method for determining the optimum number of clusters was the Calinski-Harabazs index and the elbow method as a follow up to confirm the findings of the Calinski-Harabazs method. Traditional \textit{k}-means is also extremely sensitive to the initial clusters and its accuracy is highly dependent on how far the initial cluster centers are from the true cluster centers. There were obvious implications that were evident in the accuracy scores in some of the data sets. We were able to address and analyze the effects of the same in this project.
\par
We were also able to stress-test the algorithm with a high dimensional data to confirm its validity. Initially the synthesis of this proposed algorithm was based on a 2 or 3-dimensional data with a gaussian distribution but by testing the algorithm with a high dimensional data set, we were able to see that the proposed algorithm is robust enough to cluster high dimensional data with a higher accuracy than its traditional counterpart. We also saw a trend with the synthetic data sets where the data sets with a higher variance had a higher overall accuracy. The validity of this claim is yet to be explored in its full capacity but this project definitely sets up the precedent for the same. Overall, the proposed algorithm outperformed the traditional \textit{k}-means across all the data sets that were used in this research. There were instances where the overall accuracy was higher by a small amount but nonetheless, there were ample of evidences to prove our initial hypothesis correct. 
\par A number of studies also evaluated the optimization of the final clusters based on the inter-cluster distance and all of them also came to the same conclusion - the inclusion of another distance metric definitely boosts the accuracy of the traditional \textit{k}-means algorithm. Although our approach with the algorithm in this project was a little different than the rest, the results were in conjunction with the rest of the published work. 
